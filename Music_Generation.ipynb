{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1sRodikuL8DzbattfS29J-zwPC5N6HYUS",
      "authorship_tag": "ABX9TyN0usctxuPklajc4eNhXiIe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wickkey/Music-Generation-Analytics-Project/blob/main/Music_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHFxzXzZze2P"
      },
      "source": [
        "import os\n",
        "import json \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import *\n",
        "from music21 import *\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRkClLq0zigR"
      },
      "source": [
        "data_directory = \"./drive/My Drive/data/\"\n",
        "data_file = \"Data_Tunes.txt\"\n",
        "charIndex_json = 'char_to_index.json'\n",
        "BATCH_SIZE = 16\n",
        "SEQ_LENGTH = 64\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAORtnFSzvoA"
      },
      "source": [
        "def preprocess(data):\n",
        "  list1=list(data)\n",
        "  list2=['\\n','\\n','\\n']\n",
        "  ignore=['X','T','M','S','K','P']\n",
        "  i=0\n",
        "  #to remove Part1:\n",
        "  while(i<len(list1)):\n",
        "    if(((list1[i] in ignore) and (list1[i+1]==\":\"))or list1[i]=='%' ):\n",
        "      del list2[-1]\n",
        "      while(list1[i]!='\\n'):\n",
        "        i=i+1\n",
        "    list2.append(list1[i])\n",
        "    i=i+1\n",
        "  i=0\n",
        "  #to append 'Z'(start token)\n",
        "  preprocess_data=[]\n",
        "  while(i<len(list2)):\n",
        "    if(list2[i]=='\\n'and list2[i+1]=='\\n' and list2[i+2]=='\\n'):\n",
        "      preprocess_data.append('Z')\n",
        "      i=i+3\n",
        "    else:\n",
        "      preprocess_data.append(list2[i])\n",
        "      i=i+1\n",
        "  return preprocess_data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvwluY8D8yY7"
      },
      "source": [
        "def read_data(preprocess_data):\n",
        "  char_to_index = {ch: i for (i, ch) in enumerate(sorted(list(set(preprocess_data))))}\n",
        "\n",
        "    \n",
        "  with open(os.path.join(data_directory, charIndex_json), mode = \"w\") as f:\n",
        "        json.dump(char_to_index, f)\n",
        "        \n",
        "  index_to_char = {i: ch for (ch, i) in char_to_index.items()}\n",
        "  num_unique_chars = len(char_to_index)\n",
        "  all_characters_as_indices = np.asarray([char_to_index[c] for c in preprocess_data], dtype = np.int32)\n",
        "  return all_characters_as_indices,num_unique_chars"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJpRo_5b816a"
      },
      "source": [
        "def input_output(all_chars_as_indices,num_unique_chars):\n",
        "    total_length = all_chars_as_indices.shape[0]\n",
        "    num_examples=int(total_length/SEQ_LENGTH)\n",
        "    X=np.zeros((num_examples,SEQ_LENGTH))\n",
        "    Y=np.zeros((num_examples,SEQ_LENGTH,num_unique_chars))\n",
        "    for i in range(num_examples):\n",
        "      for j in range(SEQ_LENGTH):\n",
        "        X[i,j]=all_chars_as_indices[i*SEQ_LENGTH+j]\n",
        "        Y[i,j,all_chars_as_indices[i*SEQ_LENGTH+j+1]]=1\n",
        "    return X,Y"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnBv-A2p85AA"
      },
      "source": [
        "def build_model( seq_length, num_unique_chars):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Embedding(input_dim = num_unique_chars, output_dim = 512, input_shape = (seq_length,))) \n",
        "    \n",
        "    model.add(LSTM(256, return_sequences = True))\n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    model.add(LSTM(256, return_sequences = True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(256, return_sequences = True))\n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    \n",
        "    model.add(TimeDistributed(Dense(num_unique_chars)))\n",
        "\n",
        "    model.add(Activation(\"softmax\"))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCDkUDNH9AOu"
      },
      "source": [
        "def make_model(num_unique_chars):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Embedding(input_dim = num_unique_chars, output_dim = 512, batch_input_shape = (1, 1))) \n",
        "  \n",
        "# stateful: If True, the last state for each sample at index i in a batch will be used \n",
        "# as initial state for the sample of index i in the following batch.\n",
        "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    model.add(LSTM(256,return_sequences=True, stateful = True)) \n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    model.add((Dense(num_unique_chars)))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BDL_irf9By9"
      },
      "source": [
        "def generate_sequence(gen_seq_length):\n",
        "    with open(os.path.join(data_directory, charIndex_json)) as f:\n",
        "        char_to_index = json.load(f)\n",
        "    index_to_char = {i:ch for ch, i in char_to_index.items()}\n",
        "    num_unique_chars = len(index_to_char)\n",
        "    \n",
        "    model = make_model(num_unique_chars)\n",
        "    model.load_weights(\"./drive/My Drive/weights.80.hdf5\")\n",
        "     \n",
        "    sequence_index = [char_to_index['A'],char_to_index['E'],char_to_index['D'],char_to_index['#'],char_to_index['C'],char_to_index['B'],]\n",
        "\n",
        "    for _ in range(gen_seq_length):\n",
        "        batch = np.zeros((1, 1))\n",
        "        batch[0, 0] = sequence_index[-1]\n",
        "        \n",
        "        predicted_probs = model.predict_on_batch(batch).ravel()\n",
        "        sample = np.random.choice(range(num_unique_chars), size = 1, p = predicted_probs)\n",
        "        \n",
        "        \n",
        "        sequence_index.append(sample[0])\n",
        "    \n",
        "        \n",
        "    \n",
        "    seq = ''.join(index_to_char[c] for c in sequence_index)\n",
        "    seq='M:4/8\\n'+str(seq)\n",
        "    return seq"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE1EFniP9E67"
      },
      "source": [
        "def convert_to_midi(abc):\n",
        "    c = converter.subConverters.ConverterABC()\n",
        "    c.registerOutputExtensions = (\"midi\", )\n",
        "    c.parseData(abc)\n",
        "    s = c.stream\n",
        "    s.write('midi', fp='demos1.mid')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8jLBsys9HeL",
        "outputId": "ff59a628-5853-4924-8547-aaf53a602d3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "file = open(os.path.join(data_directory, data_file), mode = 'r')\n",
        "data = file.read()\n",
        "file.close()\n",
        "preprocess_data=preprocess(data)\n",
        "print(set(preprocess_data))\n",
        "all_characters_as_indices,num_unique_chars=read_data(preprocess_data)\n",
        "X,Y=input_output(all_characters_as_indices,num_unique_chars)\n",
        "print(\"length of preprocess_data-{}\".format(len(preprocess_data)))\n",
        "print(\"vocab_size={}\".format(num_unique_chars))\n",
        "print(\"all_characters={}\".format(all_characters_as_indices))\n",
        "print(\"length of all_characters-{}\".format(len(all_characters_as_indices)))\n",
        "print(\"shape of X={}\".format(X.shape))\n",
        "print(\"shape of Y={}\".format(Y.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Z', 'f', '(', '^', 't', ',', 'b', 'r', '|', ':', 'C', 'z', 'L', 'B', '!', ']', 'D', 'c', '\\n', 'u', 'o', '[', '=', '3', 'a', 's', '4', ')', '8', '\"', 'p', '-', '~', '2', 'l', '+', 'd', '1', 'F', 'i', '6', 'R', '/', 'e', 'E', 'g', '\\\\', 'G', '_', '7', 'm', 'V', '#', \"'\", 'A', 'H', 'n', '9', ' '}\n",
            "length of preprocess_data-116963\n",
            "vocab_size=59\n",
            "all_characters=[33 44 57 ... 15 20 57]\n",
            "length of all_characters-116963\n",
            "shape of X=(1827, 64)\n",
            "shape of Y=(1827, 64, 59)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1DQ9HpI9Kx4",
        "outputId": "de5d88f5-931b-46a2-f9f6-2b2afc4e7c77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model=build_model(SEQ_LENGTH,num_unique_chars)\n",
        "model.summary()\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
        "checkpoint=ModelCheckpoint(filepath='weights.{epoch:02d}.hdf5',monitor='loss',save_best_only=True,save_weights_only=True,period=1)\n",
        "model.fit(X,Y,batch_size=16,epochs=80,callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 64, 512)           30208     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64, 256)           787456    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64, 256)           525312    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64, 256)           525312    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64, 256)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 64, 59)            15163     \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 64, 59)            0         \n",
            "=================================================================\n",
            "Total params: 1,883,451\n",
            "Trainable params: 1,883,451\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/80\n",
            "115/115 [==============================] - 7s 61ms/step - loss: 3.0931 - accuracy: 0.1877\n",
            "Epoch 2/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 2.1922 - accuracy: 0.3895\n",
            "Epoch 3/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 1.8389 - accuracy: 0.4478\n",
            "Epoch 4/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 1.6656 - accuracy: 0.4743\n",
            "Epoch 5/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 1.5721 - accuracy: 0.4953\n",
            "Epoch 6/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 1.5092 - accuracy: 0.5136\n",
            "Epoch 7/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 1.4477 - accuracy: 0.5311\n",
            "Epoch 8/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 1.4004 - accuracy: 0.5425\n",
            "Epoch 9/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 1.3566 - accuracy: 0.5561\n",
            "Epoch 10/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 1.3143 - accuracy: 0.5681\n",
            "Epoch 11/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 1.2738 - accuracy: 0.5808\n",
            "Epoch 12/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 1.2394 - accuracy: 0.5931\n",
            "Epoch 13/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 1.2081 - accuracy: 0.6009\n",
            "Epoch 14/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 1.1785 - accuracy: 0.6104\n",
            "Epoch 15/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 1.1526 - accuracy: 0.6182\n",
            "Epoch 16/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 1.1221 - accuracy: 0.6278\n",
            "Epoch 17/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 1.0962 - accuracy: 0.6365\n",
            "Epoch 18/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 1.0721 - accuracy: 0.6440\n",
            "Epoch 19/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 1.0485 - accuracy: 0.6497\n",
            "Epoch 20/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 1.0270 - accuracy: 0.6588\n",
            "Epoch 21/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 1.0042 - accuracy: 0.6676\n",
            "Epoch 22/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.9815 - accuracy: 0.6748\n",
            "Epoch 23/80\n",
            "115/115 [==============================] - 7s 58ms/step - loss: 0.9607 - accuracy: 0.6809\n",
            "Epoch 24/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.9360 - accuracy: 0.6880\n",
            "Epoch 25/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.9167 - accuracy: 0.6943\n",
            "Epoch 26/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.8891 - accuracy: 0.7045\n",
            "Epoch 27/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.8718 - accuracy: 0.7086\n",
            "Epoch 28/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.8513 - accuracy: 0.7150\n",
            "Epoch 29/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.8300 - accuracy: 0.7238\n",
            "Epoch 30/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.8090 - accuracy: 0.7306\n",
            "Epoch 31/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.7893 - accuracy: 0.7366\n",
            "Epoch 32/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.7678 - accuracy: 0.7437\n",
            "Epoch 33/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.7478 - accuracy: 0.7502\n",
            "Epoch 34/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.7314 - accuracy: 0.7558\n",
            "Epoch 35/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.7165 - accuracy: 0.7604\n",
            "Epoch 36/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.6967 - accuracy: 0.7672\n",
            "Epoch 37/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.6789 - accuracy: 0.7720\n",
            "Epoch 38/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.6605 - accuracy: 0.7786\n",
            "Epoch 39/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.6460 - accuracy: 0.7831\n",
            "Epoch 40/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.6296 - accuracy: 0.7880\n",
            "Epoch 41/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.6144 - accuracy: 0.7934\n",
            "Epoch 42/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.6002 - accuracy: 0.7980\n",
            "Epoch 43/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.5889 - accuracy: 0.8020\n",
            "Epoch 44/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.5720 - accuracy: 0.8071\n",
            "Epoch 45/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.5599 - accuracy: 0.8104\n",
            "Epoch 46/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.5468 - accuracy: 0.8162\n",
            "Epoch 47/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.5374 - accuracy: 0.8186\n",
            "Epoch 48/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.5207 - accuracy: 0.8240\n",
            "Epoch 49/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.5111 - accuracy: 0.8270\n",
            "Epoch 50/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.5030 - accuracy: 0.8283\n",
            "Epoch 51/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.4912 - accuracy: 0.8340\n",
            "Epoch 52/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.4836 - accuracy: 0.8363\n",
            "Epoch 53/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.4678 - accuracy: 0.8409\n",
            "Epoch 54/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.4573 - accuracy: 0.8448\n",
            "Epoch 55/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.4536 - accuracy: 0.8454\n",
            "Epoch 56/80\n",
            "115/115 [==============================] - 7s 60ms/step - loss: 0.4427 - accuracy: 0.8484\n",
            "Epoch 57/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.4352 - accuracy: 0.8509\n",
            "Epoch 58/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.4271 - accuracy: 0.8543\n",
            "Epoch 59/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.4169 - accuracy: 0.8572\n",
            "Epoch 60/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.4154 - accuracy: 0.8586\n",
            "Epoch 61/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.4058 - accuracy: 0.8615\n",
            "Epoch 62/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.3952 - accuracy: 0.8641\n",
            "Epoch 63/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.3908 - accuracy: 0.8662\n",
            "Epoch 64/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.3897 - accuracy: 0.8658\n",
            "Epoch 65/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.3822 - accuracy: 0.8681\n",
            "Epoch 66/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.3727 - accuracy: 0.8719\n",
            "Epoch 67/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.3667 - accuracy: 0.8742\n",
            "Epoch 68/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.3609 - accuracy: 0.8764\n",
            "Epoch 69/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.3547 - accuracy: 0.8772\n",
            "Epoch 70/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.3534 - accuracy: 0.8783\n",
            "Epoch 71/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.3479 - accuracy: 0.8802\n",
            "Epoch 72/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.3447 - accuracy: 0.8813\n",
            "Epoch 73/80\n",
            "115/115 [==============================] - 7s 59ms/step - loss: 0.3358 - accuracy: 0.8842\n",
            "Epoch 74/80\n",
            "113/115 [============================>.] - ETA: 0s - loss: 0.3337 - accuracy: 0.8845"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFHl3VGo9gaa"
      },
      "source": [
        "music = generate_sequence(192)\n",
        "print(\"\\nMUSIC SEQUENCE GENERATED: \\n{}\".format(music))\n",
        "convert_to_midi(music)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtNXAB_AOmLS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}